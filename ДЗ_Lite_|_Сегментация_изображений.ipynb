{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ Lite | Сегментация изображений  ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaliban-86/AndroidHomeworksRep/blob/master/%D0%94%D0%97_Lite_%7C_%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u81YRkk6Y8su"
      },
      "source": [
        "1. На основе учебного ноутбука проведите финальную подготовку данных. Иизмените количество сегментирующих классов с `16` на `5`.\n",
        "\n",
        "2. Проведите суммарно не менее `10` экспериментов и визуализируйте их результаты (включая точность обучения сетей на одинаковом количестве эпох, например, на `7`):\n",
        "\n",
        "  - изменив `filters` в сверточных слоях\n",
        "  - изменив `kernel_size` в сверточных слоях\n",
        "  - изменив активационную функцию в скрытых слоях с `relu` на `linear` или/и `selu`, `elu`.\n",
        "\n",
        "\n",
        "**Важно!**\n",
        "\n",
        "Многие эксперименты могут приводить к переполнению ОЗУ в вашем ноутбуке и сброса кода обучения. \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "Для предотвращения переполнения ОЗУ может помочь библиотека `gc`. Вставьте строчку `gc.collect()` в цикл ваших экспериментов для сбора и удаления временных данных (кеш)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzYOKrjeRpzw"
      },
      "source": [
        "Перед выполнением задания, пожалуйста, запустите ячейку `Подготовка` ниже:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFyI8tjLV1ba"
      },
      "source": [
        "## Подготовка "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3LPRx8H9v_c"
      },
      "source": [
        "### Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KymN8bdebLzJ"
      },
      "source": [
        " # Импортируем модели keras: Model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        " # Импортируем стандартные слои keras\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, BatchNormalization, UpSampling2D\n",
        "\n",
        "# Импортируем оптимизатор Adam\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Импортируем модуль image для работы с изображениями\n",
        "from tensorflow.keras.preprocessing import image \n",
        "\n",
        "# Импортируем библиотеку numpy\n",
        "import numpy as np \n",
        "\n",
        "# Импортируем методделения выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# загрузка файлов по HTML ссылке\n",
        "import gdown\n",
        "\n",
        "# Для работы с файлами \n",
        "import os \n",
        "\n",
        "# Для генерации случайных чисел \n",
        "import random\n",
        "\n",
        "import time\n",
        "\n",
        "# импортируем модель Image для работы с изображениями\n",
        "from PIL import Image \n",
        "\n",
        "# очистка ОЗУ\n",
        "import gc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVjxntar-a5H"
      },
      "source": [
        "### Загрузка датасета\n",
        "\n",
        "грузим и распаковываем архив картинок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP4-NkAt96gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582d4f6f-8ab7-4847-fa81-1503aa1f45a2"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "\n",
        "#gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l14/construction_256x192.zip', None, quiet=False)\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l14/construction_512x384.zip', None, quiet=False)\n",
        "\n",
        "!unzip -q 'construction_256x192.zip' # распоковываем архив"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://storage.yandexcloud.net/aiueducation/Content/base/l14/construction_512x384.zip\n",
            "To: /content/construction_512x384.zip\n",
            "100%|██████████| 764M/764M [00:36<00:00, 21.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace val/original/val_original_image_00000.bmp? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNtynGfV27x"
      },
      "source": [
        "# Глобальные параметры\n",
        "\n",
        "IMG_WIDTH = 192               # Ширина картинки \n",
        "IMG_HEIGHT = 256              # Высота картинки \n",
        "NUM_CLASSES = 16              # Задаем количество классов на изображении\n",
        "TRAIN_DIRECTORY = 'train'     # Название папки с файлами обучающей выборки\n",
        "VAL_DIRECTORY = 'val'         # Название папки с файлами проверочной выборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt2yMYbdrTVP"
      },
      "source": [
        "Загрузим оригинальные изображения (код из лекции):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRDvv0-DQHwT",
        "outputId": "a553e2ff-be0f-42cc-fe6e-bd37660d26f1"
      },
      "source": [
        "train_images = [] # Создаем пустой список для хранений оригинальных изображений обучающей выборки\n",
        "val_images = [] # Создаем пустой список для хранений оригинальных изображений проверочной выборки\n",
        "\n",
        "cur_time = time.time()  # Засекаем текущее время\n",
        "\n",
        "# Проходим по всем файлам в каталоге по указанному пути  \n",
        "for filename in sorted(os.listdir(TRAIN_DIRECTORY+'/original')):   \n",
        "    # Читаем очередную картинку и добавляем ее в список изображений с указанным target_size\n",
        "    train_images.append(image.load_img(os.path.join(TRAIN_DIRECTORY+'/original',filename),\n",
        "                                       target_size=(IMG_WIDTH, IMG_HEIGHT)))               \n",
        "    \n",
        "# Отображаем время загрузки картинок обучающей выборки    \n",
        "print ('Обучающая выборка загружена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') \n",
        "\n",
        "# Отображаем количество элементов в обучающей выборке\n",
        "print ('Количество изображений: ', len(train_images)) \n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "\n",
        "# Проходим по всем файлам в каталоге по указанному пути\n",
        "for filename in sorted(os.listdir(VAL_DIRECTORY+'/original')):\n",
        "    # Читаем очередную картинку и добавляем ее в список изображений с указанным target_size   \n",
        "    val_images.append(image.load_img(os.path.join(VAL_DIRECTORY+'/original',filename), \n",
        "                                     target_size=(IMG_WIDTH, IMG_HEIGHT)))  \n",
        "\n",
        "# Отображаем время загрузки картинок проверочной выборки\n",
        "print ('Проверочная выборка загружена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') \n",
        "\n",
        "# Отображаем количество элементов в проверочной выборке\n",
        "print ('Количество изображений: ', len(val_images)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка загружена. Время загрузки: 0.27c\n",
            "Количество изображений:  1900\n",
            "Проверочная выборка загружена. Время загрузки: 0.02c\n",
            "Количество изображений:  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICqodxfPra3k"
      },
      "source": [
        "Загрузим сегментированные изображения (код из лекции):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyA-q3d5YOL5",
        "outputId": "417e37b8-1903-4de0-85b4-54b6b8ec459c"
      },
      "source": [
        "train_segments = [] # Создаем пустой список для хранений оригинальных изображений обучающей выборки\n",
        "val_segments = [] # Создаем пустой список для хранений оригинальных изображений проверочной выборки\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "\n",
        "for filename in sorted(os.listdir(TRAIN_DIRECTORY+'/segment')): # Проходим по всем файлам в каталоге по указанному пути     \n",
        "    # Читаем очередную картинку и добавляем ее в список изображений с указанным target_size  \n",
        "    train_segments.append(image.load_img(os.path.join(TRAIN_DIRECTORY+'/segment',filename),\n",
        "                                       target_size=(IMG_WIDTH, IMG_HEIGHT)))                                                     \n",
        "    \n",
        "# Отображаем время загрузки картинок обучающей выборки\n",
        "print ('Обучающая выборка загружена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') \n",
        "\n",
        "# Отображаем количество элементов в обучающем наборе сегментированных изображений\n",
        "print ('Количество изображений: ', len(train_segments)) \n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "\n",
        "for filename in sorted(os.listdir(VAL_DIRECTORY+'/segment')): # Проходим по всем файлам в каталоге по указанному пути\n",
        "    # Читаем очередную картинку и добавляем ее в список изображений с указанным target_size                                                      \n",
        "    val_segments.append(image.load_img(os.path.join(VAL_DIRECTORY+'/segment',filename), \n",
        "                                     target_size=(IMG_WIDTH, IMG_HEIGHT)))  \n",
        "\n",
        "# Отображаем время загрузки картинок проверочной выборки\n",
        "print ('Проверочная выборка загружена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='')\n",
        "\n",
        "# Отображаем количество элементов в проверочном наборе сегментированных изображений\n",
        "print ('Количество изображений: ', len(val_segments)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка загружена. Время загрузки: 0.24c\n",
            "Количество изображений:  1900\n",
            "Проверочная выборка загружена. Время загрузки: 0.02c\n",
            "Количество изображений:  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQdPRE5OYLE-"
      },
      "source": [
        "## Решение\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3yC0JWQRF-g"
      },
      "source": [
        "# Ваше решение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLOOR = (100, 100, 100)         # Пол (серый)\n",
        "CEILING = (0, 0, 100)           # Потолок (синий)\n",
        "WALL = (0, 100, 0)              # Стена (зеленый)\n",
        "COLUMN = (100, 0, 0)            # Колонна (красный)\n",
        "APERTURE = (0, 100, 100)        # Проем (темно-бирюзовый)\n",
        "DOOR = (100, 0, 100)            # Дверь (бордовый)\n",
        "WINDOW = (100, 100, 0)          # Окно (золотой)\n",
        "EXTERNAL = (200, 200, 200)      # Внешний мир (светло-серый)\n",
        "RAILINGS = (0, 200, 0)          # Перила (светло-зеленый)\n",
        "BATTERY = (200, 0, 0)           # Батареи (светло-красный)\n",
        "PEOPLE = (0, 200, 200)          # Люди (бирюзовый)\n",
        "LADDER = (0, 0, 200)            # Лестница (светло-синий)\n",
        "INVENTORY = (200, 0, 200)       # Инвентарь (розовый)\n",
        "LAMP = (200, 200, 0)            # Лампа (желтый)\n",
        "WIRE = (0, 100, 200)            # Провод (голубой)\n",
        "BEAM = (100, 0, 200)            # Балка (фиолетовый)\n",
        "\n",
        "CLASSES = (FLOOR, CEILING, WALL, COLUMN, APERTURE, DOOR, WINDOW, EXTERNAL, RAILINGS, BATTERY, PEOPLE, LADDER, INVENTORY, LAMP, WIRE, BEAM)"
      ],
      "metadata": {
        "id": "2BvBYHJkmI9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjc_kwSbmrS4",
        "outputId": "20f5d32c-d4d1-411e-b451-b08991eda858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "187"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain = [] # Создаем пустой список под обучающую выборку\n",
        "xVal = [] # Создаем пустой список под проверочную выборку\n",
        "\n",
        "for img in train_images: # Проходим по всем изображениям из train_images\n",
        "  # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "  x = image.img_to_array(img) \n",
        "  xTrain.append(x) # Добавляем очередной элемент в xTrain\n",
        "\n",
        "for img in val_images: # Проходим по всем изображениям из val_images\n",
        "  # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "  x = image.img_to_array(img) \n",
        "  xVal.append(x) # Добавляем очередной элемент в xTrain\n",
        "\n",
        "xTrain = np.array(xTrain) # Переводим в numpy\n",
        "print(xTrain.shape) # Размер xTrain\n",
        "\n",
        "xVal = np.array(xVal) # Переводим в numpy\n",
        "print(xVal.shape) # Размер xVal"
      ],
      "metadata": {
        "id": "iySVKFrcmI6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1324c453-3ee3-475a-f3d6-0194f96055bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1900, 192, 256, 3)\n",
            "(100, 192, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment2channel(data):\n",
        "\n",
        "  y_result = []\n",
        "  \n",
        "  for d in data: # берем RGB картику\n",
        "    sample = np.array(d)\n",
        "    # создаем пустую 1-канальную картику\n",
        "    y = np.zeros((IMG_WIDTH, IMG_HEIGHT, 1)).astype('int')\n",
        "    \n",
        "    for i, cl in enumerate(CLASSES): # берем класс и номер класса\n",
        "      # сравниваем 3-х канальный  пиксель и класс и присваиваем номер класса\n",
        "      y[np.where(np.all(sample==CLASSES[i], axis=-1))] = i \n",
        "    y_result.append(y)\n",
        "  \n",
        "  return np.array(y_result)"
      ],
      "metadata": {
        "id": "JgtRua6lmI3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def channel2segment(data):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for y in data: # берем 1-канальную картинку\n",
        "    # создаем пустую 3х канальную картику\n",
        "    temp = np.zeros((IMG_WIDTH, IMG_HEIGHT, 3)).astype('int') \n",
        "    \n",
        "    for i, cl in enumerate(CLASSES): # берем класс и номер класса\n",
        "      # сравниваем, заполняем 3 канала значением из CLASSES[i]\n",
        "      temp[np.where(np.all(y==i, axis=-1))] = CLASSES[i]\n",
        "    result.append(temp)\n",
        "  \n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "OO6pJmotmI07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain = segment2channel(train_segments)\n",
        "yVal = segment2channel(val_segments)\n",
        "\n",
        "print(yTrain.shape)\n",
        "print(yVal.shape)"
      ],
      "metadata": {
        "id": "SOmh0iYkmIa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a881d7a-f4bc-446f-8f83-e76a17be6380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1900, 192, 256, 1)\n",
            "(100, 192, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQfQMmOjqRnc",
        "outputId": "64b06952-eb6d-4d14-8d8b-c8dc0be9d246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain5 = yTrain.copy()\n",
        "yTrain5[(yTrain5 > 2) & (yTrain5 != 12)] = 3\n",
        "yTrain5[yTrain5==12] = 4\n",
        "\n",
        "yVal5 = yVal.copy()\n",
        "yVal5[(yVal5 > 2) & (yVal5 != 12)] = 3\n",
        "yVal5[yVal5==12] = 4\n",
        "\n",
        "NUM_CLASSES = 5 "
      ],
      "metadata": {
        "id": "AluTMVgHqRkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_linearSegmentationNet(\n",
        "      num_classes = 5,            # количество классов\n",
        "      input_shape = (176, 240, 3) # размерность карты сегментации\n",
        "      ):\n",
        "  \n",
        "    img_input = Input(input_shape) # Создаем входной слой с размерностью input_shape\n",
        "    x = Conv2D(filters[0], kernel_size=kernel_size,\n",
        "               padding='same', name='block1_conv1')(img_input)     # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation(activ)(x)   \n",
        "\n",
        "    x = Conv2D(filters[1], kernel_size=kernel_size,\n",
        "               padding='same', name='block1_conv3')(x) # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation(activ)(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(filters[2], kernel_size=kernel_size,\n",
        "               padding='same',name='block1_conv4')(x) # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation(activ)(x)     \n",
        "\n",
        "    x = Conv2D(filters[3], kernel_size=kernel_size,\n",
        "               padding='same', name='block1_conv5')(x) # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation(activ)(x)           \n",
        "       \n",
        "    x = Conv2D(num_classes, kernel_size = kernel_size,\n",
        "               activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    \n",
        "    # Возвращаем сформированную модель\n",
        "    return model "
      ],
      "metadata": {
        "id": "nK3nAraLqRb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Список для сохранения точности сети при заданных параметрах\n",
        "data_list = []\n",
        "\n",
        "# количество экспериментов\n",
        "experiments = 12\n",
        "\n",
        "# количество эпох в эксперименте\n",
        "epochs = 7\n",
        "\n",
        "# списки для тестируемых параметров для случайного выбора\n",
        "filters_lst = (8, 16, 32, 64, 128)\n",
        "kernel_lst = ((2,2),(3, 3), (2, 3), (3, 2))\n",
        "activ_lst = ('relu', 'linear','selu','elu')\n",
        "\n",
        "# проводим эксперименты\n",
        "for exp in range(experiments):\n",
        "    \n",
        "    gc.collect()\n",
        "\n",
        "    # определяем случайно параметры сети методом \n",
        "    filters = [random.choice(filters_lst) for i in range(4)]\n",
        "    activ = random.choice(activ_lst)\n",
        "    kernel_size = random.choice(kernel_lst)\n",
        "\n",
        "    # Создание сети с текущим количеством нейронов и активацией\n",
        "    model = test_linearSegmentationNet(NUM_CLASSES,\n",
        "                                      (IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    \n",
        "    # Вывод структуры модели\n",
        "    print(model.summary()) \n",
        "\n",
        "    # Вывод текущих параметров сети\n",
        "    print(f'filters: {filters}, kernel: {kernel_size}, activ: {activ}')\n",
        "\n",
        "    # Обучение модели\n",
        "    history = model.fit(xTrain, yTrain5, \n",
        "                        validation_data=(xVal, yVal5),\n",
        "                        batch_size=6,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        shuffle=True)\n",
        "    \n",
        "    # Сохранение параметров и точности сети\n",
        "    data_list.append(('Validation accuracy:', round(history.history['sparse_categorical_accuracy'][epochs-1], 3),\n",
        "                      'filters:', filters,\n",
        "                      'kernel:', kernel_size,\n",
        "                      'activ:', activ, \n",
        "                      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzdEtkAitBHs",
        "outputId": "cfb4d372-f642-4619-c61b-9a50e21ec773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 16)      208       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 192, 256, 16)     64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 64)      4160      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 192, 256, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 8)       2056      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 192, 256, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 8)       264       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 192, 256, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 192, 256, 5)       165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,237\n",
            "Trainable params: 7,045\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [16, 64, 8, 8], kernel: (2, 2), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 24s 38ms/step - loss: 1.4615 - sparse_categorical_accuracy: 0.4349 - val_loss: 1.4467 - val_sparse_categorical_accuracy: 0.4673\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 12s 37ms/step - loss: 1.3093 - sparse_categorical_accuracy: 0.5229 - val_loss: 1.4547 - val_sparse_categorical_accuracy: 0.4678\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 12s 37ms/step - loss: 1.3039 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.4729 - val_sparse_categorical_accuracy: 0.4685\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 12s 37ms/step - loss: 1.3034 - sparse_categorical_accuracy: 0.5238 - val_loss: 1.4825 - val_sparse_categorical_accuracy: 0.4663\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 12s 37ms/step - loss: 1.3016 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.4497 - val_sparse_categorical_accuracy: 0.4686\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 12s 38ms/step - loss: 1.3015 - sparse_categorical_accuracy: 0.5240 - val_loss: 1.4497 - val_sparse_categorical_accuracy: 0.4750\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 12s 38ms/step - loss: 1.3008 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.4653 - val_sparse_categorical_accuracy: 0.4689\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 32)      416       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 192, 256, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 32)      4128      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 192, 256, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 128)     16512     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 192, 256, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 32)      16416     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 192, 256, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 192, 256, 5)       645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,013\n",
            "Trainable params: 38,565\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [32, 32, 128, 32], kernel: (2, 2), activ: relu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 29s 88ms/step - loss: 1.2283 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.4435 - val_sparse_categorical_accuracy: 0.3721\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 27s 87ms/step - loss: 1.1591 - sparse_categorical_accuracy: 0.5568 - val_loss: 1.3867 - val_sparse_categorical_accuracy: 0.4460\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 27s 85ms/step - loss: 1.1223 - sparse_categorical_accuracy: 0.5716 - val_loss: 1.5291 - val_sparse_categorical_accuracy: 0.3069\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 27s 86ms/step - loss: 1.1021 - sparse_categorical_accuracy: 0.5819 - val_loss: 1.3615 - val_sparse_categorical_accuracy: 0.4476\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 27s 86ms/step - loss: 1.0894 - sparse_categorical_accuracy: 0.5851 - val_loss: 1.3110 - val_sparse_categorical_accuracy: 0.4701\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 27s 86ms/step - loss: 1.0803 - sparse_categorical_accuracy: 0.5897 - val_loss: 1.4561 - val_sparse_categorical_accuracy: 0.4245\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 27s 86ms/step - loss: 1.0719 - sparse_categorical_accuracy: 0.5932 - val_loss: 1.3107 - val_sparse_categorical_accuracy: 0.4827\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 64)      1216      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 192, 256, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 64)      24640     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 192, 256, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 8)       3080      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 8)       392       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 192, 256, 5)       245       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,149\n",
            "Trainable params: 29,861\n",
            "Non-trainable params: 288\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [64, 64, 8, 8], kernel: (2, 3), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 21s 64ms/step - loss: 1.4247 - sparse_categorical_accuracy: 0.4513 - val_loss: 1.4405 - val_sparse_categorical_accuracy: 0.4678\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 20s 63ms/step - loss: 1.3071 - sparse_categorical_accuracy: 0.5237 - val_loss: 1.4908 - val_sparse_categorical_accuracy: 0.4572\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3039 - sparse_categorical_accuracy: 0.5229 - val_loss: 1.4704 - val_sparse_categorical_accuracy: 0.4690\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 20s 63ms/step - loss: 1.3034 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.4556 - val_sparse_categorical_accuracy: 0.4694\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3029 - sparse_categorical_accuracy: 0.5239 - val_loss: 1.4506 - val_sparse_categorical_accuracy: 0.4679\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3011 - sparse_categorical_accuracy: 0.5259 - val_loss: 1.4803 - val_sparse_categorical_accuracy: 0.4727\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3019 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.4781 - val_sparse_categorical_accuracy: 0.4566\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 32)      416       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 64)      8256      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 64)      16448     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 64)      16448     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 192, 256, 5)       1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,749\n",
            "Trainable params: 43,301\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [32, 64, 64, 64], kernel: (2, 2), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 30s 91ms/step - loss: 1.3755 - sparse_categorical_accuracy: 0.4871 - val_loss: 1.5153 - val_sparse_categorical_accuracy: 0.4468\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 28s 90ms/step - loss: 1.3144 - sparse_categorical_accuracy: 0.5264 - val_loss: 1.4972 - val_sparse_categorical_accuracy: 0.4700\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 28s 89ms/step - loss: 1.3133 - sparse_categorical_accuracy: 0.5261 - val_loss: 1.4784 - val_sparse_categorical_accuracy: 0.4659\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 28s 89ms/step - loss: 1.3140 - sparse_categorical_accuracy: 0.5244 - val_loss: 1.4927 - val_sparse_categorical_accuracy: 0.4724\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 28s 89ms/step - loss: 1.3107 - sparse_categorical_accuracy: 0.5276 - val_loss: 1.4514 - val_sparse_categorical_accuracy: 0.4692\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 28s 89ms/step - loss: 1.3068 - sparse_categorical_accuracy: 0.5254 - val_loss: 1.5427 - val_sparse_categorical_accuracy: 0.4583\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 28s 89ms/step - loss: 1.3109 - sparse_categorical_accuracy: 0.5261 - val_loss: 1.4430 - val_sparse_categorical_accuracy: 0.4682\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 128)     2432      \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 128)     98432     \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 128)     98432     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 32)      24608     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 192, 256, 5)       965       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 226,533\n",
            "Trainable params: 225,701\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [128, 128, 128, 32], kernel: (2, 3), activ: relu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 66s 204ms/step - loss: 1.2199 - sparse_categorical_accuracy: 0.5384 - val_loss: 2.0455 - val_sparse_categorical_accuracy: 0.2828\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 64s 201ms/step - loss: 1.1323 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.4878 - val_sparse_categorical_accuracy: 0.3458\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 64s 200ms/step - loss: 1.0948 - sparse_categorical_accuracy: 0.5800 - val_loss: 1.7388 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 64s 201ms/step - loss: 1.0726 - sparse_categorical_accuracy: 0.5894 - val_loss: 1.4203 - val_sparse_categorical_accuracy: 0.3912\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 64s 201ms/step - loss: 1.0636 - sparse_categorical_accuracy: 0.5934 - val_loss: 1.4000 - val_sparse_categorical_accuracy: 0.4569\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 64s 201ms/step - loss: 1.0461 - sparse_categorical_accuracy: 0.6008 - val_loss: 2.0314 - val_sparse_categorical_accuracy: 0.2522\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 64s 201ms/step - loss: 1.0313 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.6698 - val_sparse_categorical_accuracy: 0.2500\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 16)      448       \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 16)      2320      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 128)     18560     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 128)     147584    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 192, 256, 5)       5765      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 175,829\n",
            "Trainable params: 175,253\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [16, 16, 128, 128], kernel: (3, 3), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 35s 103ms/step - loss: 1.4121 - sparse_categorical_accuracy: 0.4764 - val_loss: 1.5249 - val_sparse_categorical_accuracy: 0.4430\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 31s 98ms/step - loss: 1.3308 - sparse_categorical_accuracy: 0.5208 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.4630\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 31s 97ms/step - loss: 1.3148 - sparse_categorical_accuracy: 0.5226 - val_loss: 1.5204 - val_sparse_categorical_accuracy: 0.4552\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 31s 98ms/step - loss: 1.3106 - sparse_categorical_accuracy: 0.5244 - val_loss: 1.4469 - val_sparse_categorical_accuracy: 0.4774\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 31s 97ms/step - loss: 1.3091 - sparse_categorical_accuracy: 0.5274 - val_loss: 1.5846 - val_sparse_categorical_accuracy: 0.4388\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 31s 98ms/step - loss: 1.3018 - sparse_categorical_accuracy: 0.5272 - val_loss: 1.4646 - val_sparse_categorical_accuracy: 0.4638\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 31s 98ms/step - loss: 1.3025 - sparse_categorical_accuracy: 0.5257 - val_loss: 1.4656 - val_sparse_categorical_accuracy: 0.4849\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 128)     36992     \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 64)      73792     \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 192, 256, 5)       2885      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152,645\n",
            "Trainable params: 152,069\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [32, 128, 64, 64], kernel: (3, 3), activ: relu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 34s 100ms/step - loss: 1.1816 - sparse_categorical_accuracy: 0.5454 - val_loss: 1.5009 - val_sparse_categorical_accuracy: 0.2873\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 30s 96ms/step - loss: 1.0789 - sparse_categorical_accuracy: 0.5850 - val_loss: 1.4982 - val_sparse_categorical_accuracy: 0.3055\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 30s 95ms/step - loss: 1.0423 - sparse_categorical_accuracy: 0.5982 - val_loss: 1.4166 - val_sparse_categorical_accuracy: 0.4830\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 30s 96ms/step - loss: 1.0112 - sparse_categorical_accuracy: 0.6139 - val_loss: 1.4040 - val_sparse_categorical_accuracy: 0.4829\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 30s 95ms/step - loss: 0.9934 - sparse_categorical_accuracy: 0.6203 - val_loss: 1.4884 - val_sparse_categorical_accuracy: 0.4400\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 30s 95ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.6257 - val_loss: 1.2925 - val_sparse_categorical_accuracy: 0.4409\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 30s 95ms/step - loss: 0.9640 - sparse_categorical_accuracy: 0.6328 - val_loss: 1.2417 - val_sparse_categorical_accuracy: 0.5088\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 32)      416       \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 128)     16512     \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 64)      32832     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 64)      16448     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 192, 256, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 192, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 192, 256, 5)       1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,645\n",
            "Trainable params: 68,069\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [32, 128, 64, 64], kernel: (2, 2), activ: relu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 40s 125ms/step - loss: 1.2247 - sparse_categorical_accuracy: 0.5349 - val_loss: 1.4478 - val_sparse_categorical_accuracy: 0.3597\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.1501 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.3854 - val_sparse_categorical_accuracy: 0.4694\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.1187 - sparse_categorical_accuracy: 0.5736 - val_loss: 1.3302 - val_sparse_categorical_accuracy: 0.4754\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.0979 - sparse_categorical_accuracy: 0.5824 - val_loss: 1.4503 - val_sparse_categorical_accuracy: 0.4788\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.0835 - sparse_categorical_accuracy: 0.5872 - val_loss: 1.3375 - val_sparse_categorical_accuracy: 0.4710\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.0735 - sparse_categorical_accuracy: 0.5930 - val_loss: 1.3269 - val_sparse_categorical_accuracy: 0.4750\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 39s 123ms/step - loss: 1.0671 - sparse_categorical_accuracy: 0.5962 - val_loss: 1.2990 - val_sparse_categorical_accuracy: 0.4825\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 16)      208       \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 128)     8320      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 8)       4104      \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 8)       264       \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 192, 256, 5)       165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,701\n",
            "Trainable params: 13,381\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [16, 128, 8, 8], kernel: (2, 2), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 21s 64ms/step - loss: 1.4159 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.4921 - val_sparse_categorical_accuracy: 0.4710\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3061 - sparse_categorical_accuracy: 0.5238 - val_loss: 1.4873 - val_sparse_categorical_accuracy: 0.4642\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3037 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.4564 - val_sparse_categorical_accuracy: 0.4689\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 19s 61ms/step - loss: 1.3029 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.4417 - val_sparse_categorical_accuracy: 0.4682\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3017 - sparse_categorical_accuracy: 0.5247 - val_loss: 1.4545 - val_sparse_categorical_accuracy: 0.4766\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3018 - sparse_categorical_accuracy: 0.5229 - val_loss: 1.4605 - val_sparse_categorical_accuracy: 0.4687\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 20s 62ms/step - loss: 1.3024 - sparse_categorical_accuracy: 0.5240 - val_loss: 1.4923 - val_sparse_categorical_accuracy: 0.4691\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 32)      608       \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 16)      3088      \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 16)      1552      \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 16)      1552      \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 192, 256, 5)       485       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,605\n",
            "Trainable params: 7,445\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [32, 16, 16, 16], kernel: (3, 2), activ: linear\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 14s 43ms/step - loss: 1.3985 - sparse_categorical_accuracy: 0.4661 - val_loss: 1.6276 - val_sparse_categorical_accuracy: 0.4068\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2977 - sparse_categorical_accuracy: 0.5267 - val_loss: 1.4390 - val_sparse_categorical_accuracy: 0.4828\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2930 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.4505 - val_sparse_categorical_accuracy: 0.4693\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2914 - sparse_categorical_accuracy: 0.5297 - val_loss: 1.4520 - val_sparse_categorical_accuracy: 0.4685\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2908 - sparse_categorical_accuracy: 0.5277 - val_loss: 1.4466 - val_sparse_categorical_accuracy: 0.4790\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2907 - sparse_categorical_accuracy: 0.5288 - val_loss: 1.4371 - val_sparse_categorical_accuracy: 0.4759\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 13s 42ms/step - loss: 1.2902 - sparse_categorical_accuracy: 0.5294 - val_loss: 1.4214 - val_sparse_categorical_accuracy: 0.4787\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 8)       152       \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 8)       392       \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 32)      1568      \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 16)      3088      \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 192, 256, 5)       485       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,941\n",
            "Trainable params: 5,813\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [8, 8, 32, 16], kernel: (2, 3), activ: relu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 12s 35ms/step - loss: 1.2657 - sparse_categorical_accuracy: 0.5228 - val_loss: 1.3801 - val_sparse_categorical_accuracy: 0.4658\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1948 - sparse_categorical_accuracy: 0.5437 - val_loss: 1.3763 - val_sparse_categorical_accuracy: 0.4631\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1662 - sparse_categorical_accuracy: 0.5522 - val_loss: 1.3594 - val_sparse_categorical_accuracy: 0.4607\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1446 - sparse_categorical_accuracy: 0.5600 - val_loss: 1.3560 - val_sparse_categorical_accuracy: 0.4601\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1285 - sparse_categorical_accuracy: 0.5663 - val_loss: 1.3145 - val_sparse_categorical_accuracy: 0.4725\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1199 - sparse_categorical_accuracy: 0.5701 - val_loss: 1.3056 - val_sparse_categorical_accuracy: 0.4725\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 11s 34ms/step - loss: 1.1119 - sparse_categorical_accuracy: 0.5727 - val_loss: 1.3179 - val_sparse_categorical_accuracy: 0.4673\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 192, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 256, 8)       152       \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 192, 256, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 192, 256, 8)       0         \n",
            "                                                                 \n",
            " block1_conv3 (Conv2D)       (None, 192, 256, 16)      784       \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 192, 256, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 192, 256, 16)      0         \n",
            "                                                                 \n",
            " block1_conv4 (Conv2D)       (None, 192, 256, 128)     12416     \n",
            "                                                                 \n",
            " batch_normalization_46 (Bat  (None, 192, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_46 (Activation)  (None, 192, 256, 128)     0         \n",
            "                                                                 \n",
            " block1_conv5 (Conv2D)       (None, 192, 256, 32)      24608     \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 192, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_47 (Activation)  (None, 192, 256, 32)      0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 192, 256, 5)       965       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,661\n",
            "Trainable params: 39,293\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n",
            "None\n",
            "filters: [8, 16, 128, 32], kernel: (3, 2), activ: elu\n",
            "Epoch 1/7\n",
            "317/317 [==============================] - 31s 93ms/step - loss: 1.2715 - sparse_categorical_accuracy: 0.5145 - val_loss: 1.4586 - val_sparse_categorical_accuracy: 0.4273\n",
            "Epoch 2/7\n",
            "317/317 [==============================] - 29s 91ms/step - loss: 1.1849 - sparse_categorical_accuracy: 0.5481 - val_loss: 1.3948 - val_sparse_categorical_accuracy: 0.4654\n",
            "Epoch 3/7\n",
            "317/317 [==============================] - 29s 91ms/step - loss: 1.1502 - sparse_categorical_accuracy: 0.5611 - val_loss: 1.3776 - val_sparse_categorical_accuracy: 0.4744\n",
            "Epoch 4/7\n",
            "317/317 [==============================] - 29s 91ms/step - loss: 1.1315 - sparse_categorical_accuracy: 0.5679 - val_loss: 1.3671 - val_sparse_categorical_accuracy: 0.4789\n",
            "Epoch 5/7\n",
            "317/317 [==============================] - 29s 91ms/step - loss: 1.1166 - sparse_categorical_accuracy: 0.5728 - val_loss: 1.3909 - val_sparse_categorical_accuracy: 0.4719\n",
            "Epoch 6/7\n",
            "317/317 [==============================] - 29s 92ms/step - loss: 1.1021 - sparse_categorical_accuracy: 0.5804 - val_loss: 1.4756 - val_sparse_categorical_accuracy: 0.3984\n",
            "Epoch 7/7\n",
            "317/317 [==============================] - 29s 91ms/step - loss: 1.0971 - sparse_categorical_accuracy: 0.5811 - val_loss: 1.3669 - val_sparse_categorical_accuracy: 0.4758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data_list:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNcFQC5qtBEl",
        "outputId": "00e5ecc0-2b83-4d33-e3aa-441ad3606997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Validation accuracy:', 0.524, 'filters:', [16, 64, 8, 8], 'kernel:', (2, 2), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.593, 'filters:', [32, 32, 128, 32], 'kernel:', (2, 2), 'activ:', 'relu')\n",
            "('Validation accuracy:', 0.525, 'filters:', [64, 64, 8, 8], 'kernel:', (2, 3), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.526, 'filters:', [32, 64, 64, 64], 'kernel:', (2, 2), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.607, 'filters:', [128, 128, 128, 32], 'kernel:', (2, 3), 'activ:', 'relu')\n",
            "('Validation accuracy:', 0.526, 'filters:', [16, 16, 128, 128], 'kernel:', (3, 3), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.633, 'filters:', [32, 128, 64, 64], 'kernel:', (3, 3), 'activ:', 'relu')\n",
            "('Validation accuracy:', 0.596, 'filters:', [32, 128, 64, 64], 'kernel:', (2, 2), 'activ:', 'relu')\n",
            "('Validation accuracy:', 0.524, 'filters:', [16, 128, 8, 8], 'kernel:', (2, 2), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.529, 'filters:', [32, 16, 16, 16], 'kernel:', (3, 2), 'activ:', 'linear')\n",
            "('Validation accuracy:', 0.573, 'filters:', [8, 8, 32, 16], 'kernel:', (2, 3), 'activ:', 'relu')\n",
            "('Validation accuracy:', 0.581, 'filters:', [8, 16, 128, 32], 'kernel:', (3, 2), 'activ:', 'elu')\n"
          ]
        }
      ]
    }
  ]
}